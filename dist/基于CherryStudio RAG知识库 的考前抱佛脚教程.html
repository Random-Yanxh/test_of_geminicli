<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>基于CherryStudio RAG知识库 的考前抱佛脚教程</title>
    <link rel="stylesheet" href="css/style.css">
    
    <link rel="stylesheet" href="css/themes/tech.css">
    
</head>
<body>
    <div class="container">
        <header>
            <h1>基于CherryStudio RAG知识库 的考前抱佛脚教程</h1>
            
                <p>作者：user | 发布于：2025/6/29</p>
            
        </header>
        <hr>
        <main>
            <h2>前言</h2>
<p>刚刚结束了两门专业课的考试，在考前复习的时候，我遇到了如下问题：</p>
<ol>
<li>98回忆版的<strong>历年卷往往没有答案</strong>，如果你没有一个能把历年卷答案做对的大佬朋友，复习起来可能会比较吃力。</li>
<li>对于一些要背书比较多，比较考察概念掌握和名词解释的课程，在课件、课本PDF中<code>Ctrl+F</code>搜索可能就可以解决很大一部分问题。但是当你想要把一些名词概念放在一起辨析比较，或者课本上关于某一概念的内容比较分散时，整理起来就会很麻烦。如果交给AI，其表述很可能与课件、课本不符，而且容易出现幻觉。</li>
<li>进一步，如果你想依赖AI，把所有课件整合成一个PDF或者把课本的PDF丢上去，那么在网页端，除了Google的Gemini模型支持超长的上下文，其他的诸如DeepSeek，Qwen等模型均可能出现上下文长度不够难以解析全文，或者响应超时等尴尬的问题。</li>
</ol>
<p>在上学期期末的时候我就尝试过，用下面的这套方案来对毛概和控制理论进行复习。控制理论的历年卷中就有一些简答题，没有标准答案，很难复习；而且由于其不是单纯的背书课，在书上直接Ctrl+F找效率很低，直接问AI容易出错。借着DeepSeek V3刚出世的东风（那个时候我就比较推它了），我把一些历年卷的简答题拿知识库跑了一遍，最后看起来效果，勉勉强强。
这次高电压考前我发现，CherryStudio更新了知识库的功能，虽然还是有各种问题，但总体用起来更顺手了，拿来整理了几份历年卷感觉正确率也不错。因此考完之后马上写一份教程，希望能帮到各位（可能到来的这周末的考试）。</p>
<h2>依赖</h2>
<ol>
<li>最新版<a href="https://cherry-ai.com/">Cherry Studio</a></li>
<li>免费的嵌入和重排模型（可以是来自硅基流动的 BAAI/bge-m3 和 BAAI/bge-reranker-v2-m3）</li>
<li>免费的chat API，最好是<strong>按次数免费</strong>而非给免费tokens，因为知识库消耗tokens还是很快的。可以是来自<a href="https://openrouter.ai/">OpenRouter</a> 的free DeepSeek-V3-0324，一个普通账户每日可以免费调用50次，或者Gemini的api(可以通过<a href="aistudio.google.com">aistudio</a>来调用)</li>
<li>能够对教材和课件PDF进行<strong>OCR</strong>的手段（可以是Acrobat或者<del>盗版</del>福昕PDF阅读器，或者是<a href="https://www.ilovepdf.com/zh-cn">iLovePDF | 为PDF爱好者提供的PDF文件在线处理工具</a>）只有<strong>OCR过（即能选中和编辑文本的文件）才能正常使用这一功能</strong>。<ol>
<li>这里你也可以用开源工具把PDF转为Markdown再丢进去</li>
</ol>
</li>
</ol>
<h2>原理</h2>
<p>利用嵌入和重排模型构建RAG知识库，降低幻觉和tokens消耗量，解决PDF上下文过长的问题，同时解决ctrl+F难以模糊搜索、关键词搜索难以结合上下文给出结论的痛点。我称其为“<strong>增强搜索</strong>”。</p>
<h3>什么是RAG</h3>
<blockquote>
<p>检索增强生成模型（Retrieval-Augmented Generation，RAG）通过结合生成模型和检索模型的优势，实时从外部知识库中获取相关信息，并将其融入生成任务中，确保生成的文本既具备上下文连贯性，又包含准确的知识。这种混合架构在智能问答、信息检索与推理、以及领域特定的内容生成等场景中表现尤为出色。</p>
</blockquote>
<p>上面引用自FastGPT的官方文档<a href="https://doc.fastgpt.cn/docs/guide/knowledge_base/rag/">知识库基础原理介绍 | FastGPT</a>，fastgpt、ragflow、dify等平台对知识库的支持也挺不错，但是相对来说，CherryStudio的知识库更简单易上手，更能让<strong>AI普惠大众</strong>。</p>
<h3>RAG的工作流程</h3>
<p>RAG模型的工作流程可以总结为以下几个步骤：</p>
<ol>
<li>输入查询：用户输入问题，系统将其转化为向量表示。</li>
<li>文档检索：检索器从知识库中提取与查询最相关的文档片段，通常使用向量检索技术或BM25等传统技术进行。</li>
<li>生成答案：生成器接收检索器提供的片段，并基于这些片段生成自然语言答案。生成器不仅基于原始的用户查询，还会利用检索到的片段提供更加丰富、上下文相关的答案。</li>
<li>输出结果：生成的答案反馈给用户，这个过程确保了用户能够获得基于最新和相关信息的准确回答</li>
</ol>
<h2>使用方法</h2>
<h3>API-Key的获取</h3>
<ol>
<li><p>语言模型</p>
<ol>
<li>推荐使用OpenRouter的，直接拿Google或者Github账号登录就行，登上之后Keys-Create Key创建API key
 <img src="https://s2.loli.net/2025/04/14/rOFKTJvpgLS9QYb.png" alt="image.png"></li>
<li>也可以用Google的Gemini，量比较大，但是需要挂梯子。<ol>
<li>Google账号真得注册一个，太有用了</li>
<li>如果用2.5pro，在CherryStudio中还可能出现截断问题，解决方案是关闭<code>流式传输</code>选项</li>
<li>梯子别挂到HK去，不支持，请挂HK以外的节点</li>
</ol>
</li>
<li>CherryStudio中 设置-模型服务-找到相应的服务提供商然后输入key即可。可以在“管理”按钮搜索支持的模型列表并选择你需要调用的模型服务，没有显示的可以手动添加。OpenRouter的DeepSeek不太好找，搜一下
   <img src="https://s2.loli.net/2025/04/14/RlQJ7cuVPDdY1FT.png" alt="image.png"></li>
</ol>
</li>
<li><p>Embedding和rerank模型</p>
<ol>
<li>去<a href="https://cloud.siliconflow.cn/">硅基流动</a>搞<strong>免费</strong>的<code>BAAI/bge-m3</code>和<code>BAAI/bge-reranker-v2-m3</code>，或者我找了个0余额的key，别的模型用不了，只能用免费的模型，这两个可以直接用。<ol>
<li>设置-模型服务-硅基流动-API密钥-填入<code>sk-gweelqxdzsryrbldippmorbysbsakoyeemdqdvnfpytlrbwq</code>即可</li>
<li>最好还是用自己的key，硅基流动现在最大的用处我感觉就是拿来给我跑RAG</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3>CherryStudio中知识库的配置</h3>
<p>可以参考官方文档<a href="https://docs.cherry-ai.com/knowledge-base/knowledge-base">知识库教程 | CherryStudio</a>这里不重复了。新版同时支持了嵌入和重排模型，性能比之前会更好一些。一般来说我们的使用场景就是把PDF等文件拖进去即可。如果比较多，也可以直接添加目录，如果目录里面文件有更新的话，可以在知识库那里重新生成一下，知识库就能更新，
更新过后的知识库需要新开对话才能生效；如果你在对话过程中修改了系统提示词，同样需要新开对话才能生效；如果你觉得它回答的越来越不对劲，抓紧新开一个对话。</p>
<h3>在对话中使用知识库</h3>
<ul>
<li>没有用过CherryStudio的同学可能需要先熟悉一下它的逻辑，它有 <strong>“智能体”</strong> 和 <strong>“助手”</strong> 两个概念，可以理解为 <strong>助手</strong> 是 <strong>智能体</strong> 的一个子集，前者是你经常使用的智能体，后者你不常用的话可以不用添加到助手。</li>
<li>CherryStudio预置了很多智能体，也可以创建 <strong>我的智能体</strong> ，自定义其名称和提示词，再将其添加到 <strong>助手</strong> 列表。每一个聊天，在这里是使用 <strong>“话题”</strong> 来表示的。</li>
<li>我专门用于知识库问答的智能体设置如下，你可以把我的提示词复制进来，效果还可以：<img src="https://s2.loli.net/2025/04/14/mqGxpBj18ovVQlK.png" alt="image.png"><ul>
<li>可以给智能体预设模型及其设置，温度建议拉低（比如0），上下文数其实不需要那么多，如果你针对一个问题追问的话需要长一点，问完就走的话，设成3这样就行。这样就不用每次调用都调参数和模型了，非常便捷。</li>
<li>提示词如果正常工作，输出的引用内容会有原文片段，可以据此 Ctrl+F 再去具体位置核实。</li>
</ul>
</li>
</ul>
<p>采用了如下系统提示词，看需求和情况可以修改： </p>
<blockquote>
<p>[!NOTE]- 提示词</p>
<pre><code class="language-Markdown">你是一位专业学习辅导助手，你将协助我复习课程内容。你可以访问包含课件和笔记的知识库。请按以下方式帮助我：
1. 在回答问题时：
- 优先使用知识库中的内容作为参考
- 确保回答准确性并标注知识来源
- 用清晰的语言解释专业概念
- 适当使用公式和图示辅助说明，公式直接使用Markdown或者LaTeX渲染，并且使用Obsidian能支持的`$$`格式
- 2. 对于每个问题，请：
- 给出完整的解答
- 突出标注该主题的关键知识点
- 指出易混淆或易错的要点
- 提醒相关联的知识点，帮助建立知识体系

1. 在回答结束时：
- 总结这部分内容的重点和难点
- 建议深入学习的方向
- 提供复习建议

1. 引用内容**必须**加上来源和页码等信息，同时\&lt;引用片段原文\&gt;处需使用未概括、删减的知识库片段原文
- 如果答案来自知识库内容，请给出所在章节相应片段，即\[参考资料文件名\&lt;章节位置及页码\&gt;\]：&quot;\&lt;引用片段原文\&gt;&quot;
- 如果答案并非来自知识库内容，必须标明

请以专业、耐心的态度回答我的问题，帮助我更好地理解和掌握知识。
</code></pre>
</blockquote>
<ul>
<li>在话题中，你可以选中（多个）知识库再进行问答，如图所示知识库就用上了。<img src="https://s2.loli.net/2025/04/14/UbzSMBCa2YgXDjh.png" alt="image.png"></li>
<li>如果你想实现类似于DeepSeek这样 深度思考+联网搜索，最新版的CherryStudio支持调用网络搜索引擎如Google，Bing等的搜索结果，虽然效果不太好，但是也可以一试。试了就知道其实效果没有很好，还是需要配合相应的提示词。</li>
<li>如果你对MCP有所涉猎，知识库+MCP也是比较可行的方案，可惜我自己也没玩明白。</li>
</ul>
<h2>效果展示和对比</h2>
<p>可以做到匹配知识库内容给出回答，并注明引用出处，可以精确到某份资料、某个章节、某页、某段话，从而降低幻觉。</p>
<ul>
<li>这里统一采用了<ul>
<li>知识源：刚考完的《高电压技术》，课件669页已经过OCR处理，并有书签。</li>
<li>问题：提高气体介质电气强度的方法</li>
<li>要求：列出参考来源，并且给出其在原文件中的章节位置、页码、和具体内容</li>
<li>参考答案：（位于第二章第8节，课件里面其实是小标题直接给出了）<ul>
<li>改进电极形状以改善电场分布</li>
<li>利用空间电荷改善电场分布</li>
<li>采用屏障</li>
<li>采用高气压</li>
<li>采用高电气强度气体</li>
<li>采用高真空</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>这里先放结论吧：</strong>
总的来说，支持长上下文的Google Gemini非常强，而且理论上来说，它对单个长文件的解析应该是要比RAG好的，RAG只是对不支持长上下文的模型的一种折中吧。但是当你的文件不止一个，或者有一整个知识库多个文件的时候，强如Gemini也无能为力，这毕竟是网页端，没有那么灵活。采用RAG知识库方案的话，覆盖面可以更广，幻觉也更低一些，同时，当你这个聊天上下文很长之后，你也不用重新上传一堆文件再开始问了，直接勾选知识库即可。</p>
<table>
<thead>
<tr>
<th>源</th>
<th>评价</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Ds官网</strong></td>
<td>1.典中典服务器繁忙<br>2.大文件长上下文不好解析</td>
</tr>
<tr>
<td><strong>元宝</strong></td>
<td>可以解析，但是最终答案效果比较差，幻觉太高了</td>
</tr>
<tr>
<td><strong>Gemini-2.0-flash</strong></td>
<td>可以，就是AiStudio中UI难用了一点点，然后全英文界面需要梯子；你也可以在<a href="https://gemini.google.com">Gemini官网</a>直接用，这个的界面会更清爽</td>
</tr>
<tr>
<td><strong>知识库-Gemini</strong></td>
<td>2.5pro回答不截断的话其实非常棒，但是在CherryStudio里截断问题太严重了；2.0-flash的话本身模型能力没有那么强，稍微有点差强人意，而且对指令的遵循并没有很到位（引用内容很简短）</td>
</tr>
<tr>
<td><strong>知识库-DsV3-0324</strong></td>
<td>OpenRouter的都是保真的，V3和R1模型其实表现都还不错，看具体问题了，V3会更快响应，R1的话我嫌它有点慢。总体更推荐，它基本还是比较好地做到了指令跟随</td>
</tr>
</tbody></table>
<h3>DeepSeek官网</h3>
<p>首先文件超出字数限制
<img src="https://s2.loli.net/2025/04/14/R7AjzEBL8S1rGwe.png" alt="image.png">
然后提问，经典R1服务器繁忙
<img src="https://s2.loli.net/2025/04/14/FbGkqaLwHBPMRvC.png" alt="image.png"></p>
<h3>腾讯元宝</h3>
<p>用的混元模型，然后它倒是可以读整个PDF，但是给出的回答比较天马行空了
<img src="https://s2.loli.net/2025/04/14/4RiUALDFEu2GB3y.png" alt="image.png">
幻觉太严重了，答案也不对</p>
<h3>Gemini-2.0-flash</h3>
<p><img src="https://s2.loli.net/2025/04/14/C4qV7nhgSkXW6UM.png" alt="image.png">
也不错，百万上下文还是强。你也可以在<a href="https://gemini.google.com">Gemini官网</a>直接用，这个的界面会更清爽，但是功能不如Aistudio中来得多和强大。实测也可以达到好的效果。</p>
<h3>CherryStudio知识库</h3>
<h4>Gemini 2.0 flash(From <a href="https://aistudio.google.com/">aistudio</a>)</h4>
<p> <img src="https://s2.loli.net/2025/04/14/zKoWsQPhVj6gRkd.png" alt="image.png"></p>
<h4>DeepSeek V3-0324 (From OpenRouter)</h4>
<p><img src="https://s2.loli.net/2025/04/14/is1TfMvEKgIaxdU.png" alt="image.png">
当有多个引用源的时候，采用知识库方案可能更优。</p>
<h2>总结</h2>
<h3>局限</h3>
<ul>
<li>实际上知识库的使用还是存在一些不稳定的地方，有时也会遇到精度不高、存在一定幻觉、引用内容输出不完整、提示词不完全遵循等问题。因此，这一方案始终是 <strong>仅供参考</strong>，并不能保证正确性。</li>
<li>当前的RAG方案并不支持对图片的知识库搭建，现有的思路一般是将图片用语言描述之后，检索其描述，引用图片位置</li>
<li>RAG是把语言分割成碎片，那么其“断章取义”的可能性也必然存在，它对局部的把握可能还行，但是对整体的把握就没那么理想了，可能使用FAQ表或者长上下文模型才更好。</li>
</ul>
<h3>适用场景</h3>
<p>对我来说，其使用场景主要是我在<strong>模糊查询</strong>课程的课本、课件中的一些资料，以及做历年卷选填、简答、名词解释等题目，或者辅助我<strong>依据课程资料</strong>来理解相关概念及它们的联系。
<img src="https://s2.loli.net/2025/04/14/wMjqyd5fPDZbgJc.png" alt="image.png">
两种理论对比的表格。</p>
<p>那么除此之外，RAG知识库还能做什么呢？我个人感觉，法学和医学的同学可以在复习的时候试一试把你们的大部头教材导进去做成知识库，让其模糊搜索之后，再二次定位到课本的具体位置来核查。当前有一些法律和医药的大模型，他们可能采用的是微调的方案，效果比RAG应该更好，但是成本高、耗时长；对于我们学习来说，RAG知识库应该还挺适用的了。</p>
<p>如果大家在尝试中能够探索出更好的方案欢迎交流~</p>

        </main>
        <footer>
            <p>Generated by My Static Site Generator</p>
        </footer>
    </div>
</body>
</html>